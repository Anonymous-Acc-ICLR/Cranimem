# you can provide any llm provider and api keys here
LLM_PROVIDER=local_hf
GROQ_API_KEY=your_key_here
GOOGLE_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here
OPENAI_API_BASE=https://api-inference.huggingface.co/v1/
OLLAMA_MODEL=phi4-mini
OLLAMA_BASE_URL=http://localhost:11434
HUGGINGFACEHUB_API_TOKEN=your_token_here
HF_REPO_ID=Qwen/Qwen2.5-7B-Instruct


# Neo4j Settings
NEO4J_URI=your_neo4j_uri_here
NEO4J_USERNAME=your_neo4j_username_here
NEO4J_PASSWORD=your_neo4j_password_here


# --- Memory Tuning (Optional) ---
# Weights for the scoring function [cite: 120-121]
ALPHA_RECENCY=1.0
ALPHA_IMPORTANCE=1.0
ALPHA_RELEVANCE=1.0


MAX_INTERNAL_STATE_TOKENS=2000




